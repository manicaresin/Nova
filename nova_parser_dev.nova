
// Parser  

task parse(tokens) {
  return program()
}

task program() {

  set stmts = []

  while !end_of_file() {
    set s = statement()
    if s {
      stmts.add(s)
    }
  }

  return new ProgramNode(statements=stmts)

}

task statement() {

  if match(CLASS) {
    return parse_class()
  }

  if match(INTERFACE) {
    return parse_interface()
  }

  if match(IF) {
    return parse_if_statement()
  }

  // Other statement types...

}

// Class Parsing

task parse_class() {

  // Parses class declaration 
  // Details shown previously

  return new ClassNode(...)

}

// Interface Parsing 

task parse_interface() {

  // Parses interface declaration
  // Details shown previously

  return new InterfaceNode(...)

}

// If Statement

task parse_if_statement() {
  
  // Parses if statement
  // if, condition, body, optional else 

  return new IfStatementNode(...)

}


// Types

task parse_type() {

  if match(IDENTIFIER) {
    return new NamedTypeNode(name=parse_identifier()) 
  } else {
    return new PrimitiveTypeNode(name=token())
  }

}

// Identifiers 

task parse_identifier() {
  return token() // Assumes IDENTIFIER token
}

// Expressions

task parse_expression() {

  set left = parse_unary_expression()

  while match(PLUS, MINUS) {
    set op = token()
    set right = parse_expression() // Recurse
    left = new BinaryExpressionNode(left=left, op=op, right=right) 
  }

  return left

} 

task parse_unary_expression() {
  if match(PLUS, MINUS) {
    set op = token()
    set value = parse_unary_expression()
    return new UnaryExpressionNode(op=op, value=value)
  } else {
    return parse_primary_expression()
  }
}

task parse_primary_expression() {
  if match(IDENTIFIER) {
    return new VariableNode(name=parse_identifier())
  } else if match(NUMBER, STRING) {
    return new LiteralNode(value=token()) 
  } else if match(LPAREN) {
    consume(LPAREN)
    set value = parse_expression()
    consume(RPAREN)
    return value
  }
}

// Utilities

task match(...tokens) {
  // Match any of the given token types 
}

task consume(token) {
  // Consume the given expected token
}

task token() {
  // Get current token
}

task end_of_file() {
  // Checks if end of token stream
}

// Main

set tokens = lex(code)
set ast = parse(tokens)

// AST

task ProgramNode {
  set statements = []
}

task ClassNode {
  set name
  set fields = []
  set methods = []
}

task InterfaceNode {
  set name
  set methods = []
}

task IfStatementNode {
  set condition
  set body
  set else_body
}

task BinaryExpressionNode {
  set left
  set op
  set right
}

task UnaryExpressionNode {
  set op
  set value
}

task VariableNode {
  set name
}

task LiteralNode {
  set value
}

task NamedTypeNode {
  set name
}

task PrimitiveTypeNode {
  set name
}


task parse_lambda() {
  consume(LPAREN)  
  set params = parse_parameters()
  consume(RPAREN)
  consume(RETURN_TYPE)
  set returnType = parse_type()
  set body = block()

  return new LambdaNode(params, returnType, body) 
}

task parse_type() {
  if match(GENERIC) {
    return parse_generic_type() 
  } else {  
    //... existing type parsing ...
  }
}

task parse_generic_type() {
  consume(LT)
  set typeParams = []
  repeat {
    set param = identifier()
    typeParams.add(param)
    if !match(COMMA) {
      break
    }
    consume(COMMA)
  }
  consume(GT)
  
  return new GenericTypeNode(typeParams) 
}

task parse_annotation {
  // Parses annotations on declarations
}

task parse_expression() {
  // Updated order of operations 
  set left = ...

  if match(NULL_COALESCE) {
    // null coalescing operator  
  }

  // Rest of expression parsing
}



